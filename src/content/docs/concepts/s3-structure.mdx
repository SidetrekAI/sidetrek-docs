---
title: S3 File Structure
description: Learn about S3 file structure and how to organize your files in S3.
draft: false
---
import BashCode from '@/components/BashCode'
import MyAlert from '@/components/MyAlert'

# Understanding S3 File Structure

Amazon S3 (Simple Storage Service) is a highly scalable object storage service. S3 is a popular storage choice for Data Lakehouse architectures due to its durability, scalability, and cost-effectiveness.

But S3 does not have a local version, so we use MinIO as a drop-in replacement for S3. MinIO is perfect for this since it has an S3-compatible API and we can use the same code in both development and production environment.

## Key Components of S3

S3 has a hierarchical structure that looks like a file system (but that's actually an illusion as we'll soon see).

1. **Bucket**: This is the top-level container for storing objects in S3. Each bucket must have a globally unique name and is created in a specific AWS region.
2. **Prefix**: You can think of a prefix as a directory in a file system.
3. **Key**: The unique identifier for an object within a bucket - this is like a file name.
3. **Metadata**: This is metadata about the object stored in S3. It can include information like the object's name, size, ETag, and more.

For example, inside "family-photos" bucket, you might have a prefix named "2024" and inside that prefix, you might have an object named "birthday.jpg" and "vacation.jpg":

```plaintext
family-photos
├── 2024
│   ├── birthday.jpg
│   └── vacation.jpg
```

It looks just like a file system, but underneath, S3 is actually a flat storage system:

```plaintext
family-photos/2024/birthday.jpg
family-photos/2024/vacation.jpg
```

Prefixes just make it easier to organize and manage objects in S3.

### S3 Structure for Sidetrek Example Project

In Sidetrek example project, we have a bucket named `lakehouse` containing several objects:

```plaintext
lakehouse
└── raw
    └── orders
        ├── data
        │   ├── 00000-0-21faf50e-3a3f-47a3-9d00-997c28b6a23c.parquet
        │   ├── 00000-0-49376760-60b0-4455-8b32-1e39f7fb1db5.parquet
        │   ├── ...
        └── metadata
            ├── 00000-f90d4e22-37b9-4bc6-bd98-2f08e6258a11.metadata.json
            ├── 00001-5c8c6cf4-3fe7-478e-8add-9a8a15227783.metadata.json
            ├── ...
```

These are Iceberg related objects. 

Inside the `data` prefix, Iceberg stores the actual table data. In our example project, we store it in Parquet format (columnar storage format), but it could be any Iceberg supported formats like ORC, Avro, etc. In fact, we could even injest data as a row format like Avro and then convert it to Parquet inside the same Iceberg storage.

Inside the `metadata` prefix, Iceberg stores metadata files in JSON format. These keep track of things like manifest files, snapshot information, stats about the data for query optimization, etc.

To learn more about Apache Iceberg, check out the [Iceberg documentation](https://iceberg.apache.org/).

## Querying Iceberg Tables in Trino

The `raw` prefix in S3 in our example project matches up with Trino schema `raw`. And the `orders` prefix matches up with the table name `orders`.

So to query that data in Trino, first enter the Trino shell.

<BashCode code="sidetrek run trino shell" client:load />

You'll see `trino>` at the beginning of the line on your console.

To access the Iceberg table `orders` in the `raw` schema, you can first switch to the `raw` schema in `iceberg` catalog:

<BashCode code="trino> use iceberg.raw;" client:load />

Now you can run this command to see all the tables in the schema.

<BashCode code="trino:raw> show tables;" client:load />

```plaintext
   Table   
-----------
 customers 
 orders    
 products  
 stores    
(4 rows)
```